# -*- coding: utf-8 -*-
"""rag_pinecone_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CRZM3ZgPY_FgY-snukYSsDFWQYeg7LrW
"""

import streamlit as st
from sentence_transformers import SentenceTransformer
from transformers import pipeline
from pinecone import Pinecone, ServerlessSpec
import numpy as np

PINECONE_API_KEY = "pcsk_jAu5B_CFNwyhvsgnVd6697ekjsrNbuCWUXQD17HmPMTCUHkTiYwFLp2bfRW7LvmAPUfkD"
INDEX_NAME = "rag-index"

# Create Pinecone client
pc = Pinecone(api_key=PINECONE_API_KEY)

# Create index if not exists
existing_indexes = [index.name for index in pc.list_indexes()]
if INDEX_NAME not in existing_indexes:
    pc.create_index(
        name=INDEX_NAME,
        dimension=384,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )

# Connect to the index
index = pc.Index(INDEX_NAME)

@st.cache_resource
def load_models():
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
    generator = pipeline("text2text-generation", model="google/flan-t5-base")
    return embedder, generator

embedder, generator = load_models()

st.title(" RAG Chatbot (Pinecone + Transformers)")

data = [
    "Python is a programming language used for AI and data science.",
    "Streamlit is a Python library for creating web applications.",
    "Pinecone is a vector database for semantic search.",
    "The Earth revolves around the Sun.",
    "The largest planet in the Solar System is Jupiter."
]

embeddings = embedder.encode(data).tolist()
vectors = [(f"id-{i}", embeddings[i], {"text": data[i]}) for i in range(len(data))]
index.upsert(vectors=vectors)

query = st.text_input(" Ask your question:")

if st.button("Get Answer"):
    if not query.strip():
        st.warning("Please enter a question.")
    else:
        q_embed = embedder.encode([query]).tolist()
        res = index.query(vector=q_embed[0], top_k=1, include_metadata=True)

        if res and len(res["matches"]) > 0:
            context = res["matches"][0]["metadata"].get("text", "")
        else:
            context = "No relevant context found."

        prompt = f"Question: {query}\nContext: {context}\nAnswer:"
        answer = generator(prompt, max_length=100)[0]["generated_text"]
        st.write("**Answer:**", answer)