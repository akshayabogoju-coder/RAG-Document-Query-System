# -*- coding: utf-8 -*-
"""rag_architectute

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-4wTjdr_ZQm1EQ5jGdXdYb_0TYZ6CHzb
"""

import streamlit as st
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import faiss
import numpy as np

# Load models
@st.cache_resource
def load_models():
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
    generator = pipeline("text2text-generation", model="google/flan-t5-base")
    return embedder, generator

embedder, generator = load_models()

st.title("ğŸ“˜ RAG with FAISS (Local Retrieval-Augmented Generation)")

uploaded_file = st.file_uploader("ğŸ“‚ Upload a .txt document:", type="txt")

if uploaded_file:
    text = uploaded_file.read().decode("utf-8")
    st.success("âœ… Document loaded successfully!")
    paragraphs = [p for p in text.split("\n") if p.strip()]

    # Create embeddings
    embeddings = embedder.encode(paragraphs, show_progress_bar=True)
    d = embeddings.shape[1]
    index = faiss.IndexFlatL2(d)
    index.add(np.array(embeddings))

    query = st.text_input("ğŸ” Ask a question:")

    if st.button("Get Answer"):
        q_embed = embedder.encode([query])
        D, I = index.search(np.array(q_embed), k=1)
        context = paragraphs[I[0][0]]
        prompt = f"Question: {query}\nContext: {context}\nAnswer:"
        answer = generator(prompt, max_length=100)[0]["generated_text"]
        st.write("**Answer:**", answer)